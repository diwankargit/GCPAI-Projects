{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9dff27eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install google-cloud-storage\n",
    "#!pip install PyPDF2\n",
    "#!pip install vertexai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93fea757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67fa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "project=\"llmdemo-466101\"\n",
    "location=\"us-east1\"\n",
    "\n",
    "pdf_path=\"ACL_cricket_rule.pdf\"\n",
    "bucket_name = \"rag-vector-search-ai\"\n",
    "embed_file_path = \"cricket_embeddings.json\"\n",
    "sentence_file_path = \"criket_sentences.json\"\n",
    "index_name=\"Confulence-Embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9e0eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            if page.extract_text() is not None:\n",
    "                text += page.extract_text() + \" \"\n",
    "    sentences = [sentence.strip() for sentence in text.split('. ') if sentence.strip()]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8429ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text_embeddings(sentences) -> list: \n",
    "#   aiplatform.init(project=project,location=location)\n",
    "#   model = TextEmbeddingModel.from_pretrained(\"gemini-embedding-001\")\n",
    "#   embeddings = model.get_embeddings(sentences)\n",
    "#   vectors = [embedding.values for embedding in embeddings]\n",
    "#   return vectors\n",
    "\n",
    "\n",
    "def generate_text_embeddings(sentences, batch_size=250) -> list:\n",
    "    aiplatform.init(project=project, location=location)\n",
    "    model = TextEmbeddingModel.from_pretrained(\"gemini-embedding-001\")\n",
    "    all_vectors = []\n",
    "\n",
    "    # Helper to yield chunks of size <= batch_size\n",
    "    def batch_generator(seq, size):\n",
    "        for pos in range(0, len(seq), size):\n",
    "            yield seq[pos:pos + size]\n",
    "\n",
    "    for batch in batch_generator(sentences, batch_size):\n",
    "        embeddings = model.get_embeddings(batch)\n",
    "        vectors = [embedding.values for embedding in embeddings]\n",
    "        all_vectors.extend(vectors)\n",
    "\n",
    "    return all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b3ca792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_embeddings(pdf_path, sentence_file_path, embed_file_path):\n",
    "    def clean_text(text):\n",
    "        cleaned_text = re.sub(r'\\u2022', '', text)  # Remove bullet points\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Remove extra whitespaces and strip\n",
    "        return cleaned_text\n",
    "    \n",
    "    sentences = extract_sentences_from_pdf(pdf_path)\n",
    "    if sentences:\n",
    "        embeddings = generate_text_embeddings(sentences)\n",
    "        \n",
    "        with open(embed_file_path, 'w') as embed_file, open(sentence_file_path, 'w') as sentence_file:\n",
    "            for sentence, embedding in zip(sentences, embeddings):\n",
    "                cleaned_sentence = clean_text(sentence)\n",
    "                id = str(uuid.uuid4())\n",
    "                \n",
    "                embed_item = {\"id\": id, \"embedding\": embedding}\n",
    "                sentence_item = {\"id\": id, \"sentence\": cleaned_sentence}\n",
    "                \n",
    "                json.dump(sentence_item, sentence_file)\n",
    "                sentence_file.write('\\n') \n",
    "                json.dump(embed_item, embed_file)\n",
    "                embed_file.write('\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "acf5a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(bucket_name,file_path):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.create_bucket(bucket_name,location=location)\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.upload_from_filename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46d2247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_index(bucket_name, index_name):\n",
    "    cricketrule_idex = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name = index_name,\n",
    "    contents_delta_uri = \"gs://\"+bucket_name,\n",
    "    dimensions = 768,\n",
    "    approximate_neighbors_count = 10,\n",
    "    )\n",
    "                  \n",
    "    cricketrule_idex = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name = index_name,\n",
    "    public_endpoint_enabled = True\n",
    "    )                      \n",
    "\n",
    "    cricketrule_idex.deploy_index(\n",
    "    index = cricketrule_idex, deployed_index_id = index_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7d89d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "api_key_path=\"/Users/bhavanakajal/Documents/GitHub/GCPAI-Projects/keys/llmdemo-466101-3acdef328b4a.json\"\n",
    "\n",
    "credentials= Credentials.from_service_account_file(api_key_path)\n",
    "\n",
    "PROJECT_ID=\"llmdemo-466101\"\n",
    "REGION=\"us-east1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID,location=REGION,credentials=credentials)\n",
    "\n",
    "model=GenerativeModel(\"gemini-2.5-flash\")\n",
    "# res=model.generate_content(\"What is LLM ?\")\n",
    "# print(res.text)\n",
    "\n",
    "# ## generation config \n",
    "# from vertexai.generative_models import GenerationConfig\n",
    "\n",
    "# generation_config=GenerationConfig(\n",
    "#      temperature=0.9,\n",
    "#      top_p=1.0,\n",
    "#      top_k=32,\n",
    "#      candidate_count=1,\n",
    "#      #max_output_token=8192,\n",
    "# )\n",
    "\n",
    "# res=model.generate_content(\"Why do sunsets appear red and orange?\",generation_config=generation_config)\n",
    "# print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5dcf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_and_save_embeddings(pdf_path,sentence_file_path,embed_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "260031a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export GOOGLE_APPLICATION_CREDENTIALS=\"/Users/bhavanakajal/Documents/GitHub/GCPAI-Projects/keys/llmdemo-466101-6d1afc48f1d3.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84c0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload_file(bucket_name,sentence_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947dbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
