{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py (Streamlit frontend + backend logic + RAG with GCP Vector Search)\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from google.oauth2 import service_account\n",
    "import base64\n",
    "import json\n",
    "import uuid\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchingEngineIndexEndpoint\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index import MatchingEngineIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "PROJECT_ID = \"llmdemo-466101\"\n",
    "REGION = \"us-east1\"\n",
    "MODEL = \"gemini-1.5-pro\"\n",
    "EMBED_MODEL = \"textembedding-gecko@001\"\n",
    "JIRA_API_URL = \"https://diwankarkumar12.atlassian.net/rest/api/2/issue\"\n",
    "JIRA_EMAIL = \"diwankarkumar12@gmail.com\"\n",
    "JIRA_API_TOKEN_SECRET = \"ATATT3xFfGF0uGy-4sujxTwssEwojy0sCYiXaVuM2dAf5rXa8X0ZP8CxrUZRnk-gfuQ3XjpqH-MeFj7hm6D6dN5eyv-O5Fw4V5rtBtjY9yUx1Quwk7rqUVHnV2c7X6afxKkbfA29OIz9uG2zE3riuhsIFU6gUNRyzrC9p8PJM9Dwk6QCfbyHaRk=DB006359\"\n",
    "INDEX_ENDPOINT_NAME = \"projects/885301403345/locations/us-east1/indexEndpoints/5306089184019087360\"\n",
    "INDEX_ID = \"confulence_embeddings_1753142558399\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INIT SERVICES ---\n",
    "creds = service_account.Credentials.from_service_account_file(\"path/to/service-account.json\")\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "embed_model = TextEmbeddingModel.from_pretrained(EMBED_MODEL)\n",
    "gen_model = GenerativeModel(MODEL)\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085030cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py (Streamlit frontend + backend logic + RAG with GCP Vector Search)\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from google.oauth2 import service_account\n",
    "import base64\n",
    "import json\n",
    "import uuid\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchingEngineIndexEndpoint\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index import MatchingEngineIndex\n",
    "\n",
    "# --- CONFIG ---\n",
    "PROJECT_ID = \"llmdemo-466101\"\n",
    "REGION = \"us-east1\"\n",
    "MODEL = \"gemini-1.5-pro\"\n",
    "EMBED_MODEL = \"textembedding-gecko@001\"\n",
    "JIRA_API_URL = \"https://diwankarkumar12.atlassian.net/rest/api/2/issue\"\n",
    "JIRA_EMAIL = \"diwankarkumar12@gmail.com\"\n",
    "JIRA_API_TOKEN_SECRET = \"ATATT3xFfGF0uGy-4sujxTwssEwojy0sCYiXaVuM2dAf5rXa8X0ZP8CxrUZRnk-gfuQ3XjpqH-MeFj7hm6D6dN5eyv-O5Fw4V5rtBtjY9yUx1Quwk7rqUVHnV2c7X6afxKkbfA29OIz9uG2zE3riuhsIFU6gUNRyzrC9p8PJM9Dwk6QCfbyHaRk=DB006359\"\n",
    "INDEX_ENDPOINT_NAME = \"projects/885301403345/locations/us-east1/indexEndpoints/5306089184019087360\"\n",
    "INDEX_ID = \"confulence_embeddings_1753142558399\"\n",
    "\n",
    "# --- INIT SERVICES ---\n",
    "creds = service_account.Credentials.from_service_account_file(\"path/to/service-account.json\")\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "embed_model = TextEmbeddingModel.from_pretrained(EMBED_MODEL)\n",
    "gen_model = GenerativeModel(MODEL)\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "def extract_confluence_text(url):\n",
    "    try:\n",
    "        res = req.get(url)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        return soup.get_text()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text(text, max_words=200):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "def embed_and_store_chunks(chunks):\n",
    "    embeddings = embed_model.get_embeddings(chunks)\n",
    "    datapoints = []\n",
    "    for chunk, embedding in zip(chunks, embeddings):\n",
    "        datapoints.append(\n",
    "            MatchingEngineIndexDatapoint(\n",
    "                datapoint_id=str(uuid.uuid4()),\n",
    "                feature_vector=embedding.values,\n",
    "                metadata={\"text\": chunk}\n",
    "            )\n",
    "        )\n",
    "    index_endpoint.upsert_datapoints(\n",
    "        deployed_index_id=INDEX_ID,\n",
    "        datapoints=datapoints\n",
    "    )\n",
    "\n",
    "def query_relevant_chunks(query, top_k=3):\n",
    "    query_vec = embed_model.get_embeddings([query])[0].values\n",
    "    res = index_endpoint.find_neighbors(\n",
    "        deployed_index_id=INDEX_ID,\n",
    "        queries=[query_vec],\n",
    "        num_neighbors=top_k,\n",
    "        approximate_neighbors_count=1000,\n",
    "        return_full_datapoint=True\n",
    "    )\n",
    "    neighbors = res[0].neighbors\n",
    "    return [neighbor.datapoint.metadata[\"text\"] for neighbor in neighbors]\n",
    "\n",
    "# --- STREAMLIT UI ---\n",
    "st.title(\"üß† AI + RAG Jira Story Generator (GCP)\")\n",
    "st.markdown(\"Enter your story and supporting documentation.\")\n",
    "\n",
    "story_input = st.text_input(\"üìù One-line User Story\")\n",
    "confluence_links_input = st.text_area(\"üîó Confluence Page Links (one per line)\", height=100)\n",
    "uploaded_files = st.file_uploader(\"üìÑ Upload PDFs or Diagrams (optional)\", type=[\"pdf\", \"png\", \"jpg\", \"jpeg\"], accept_multiple_files=True)\n",
    "generate_code = st.checkbox(\"üíª Generate Code\")\n",
    "\n",
    "if st.button(\"üöÄ Generate Jira Story\"):\n",
    "    if not story_input:\n",
    "        st.warning(\"Story is required!\")\n",
    "        st.stop()\n",
    "\n",
    "    context_chunks = []\n",
    "\n",
    "    # Process all Confluence links\n",
    "    if confluence_links_input.strip():\n",
    "        for url in confluence_links_input.strip().splitlines():\n",
    "            full_text = extract_confluence_text(url.strip())\n",
    "            if full_text:\n",
    "                chunks = chunk_text(full_text)\n",
    "                embed_and_store_chunks(chunks)\n",
    "                context_chunks.extend(query_relevant_chunks(story_input))\n",
    "\n",
    "    # Process all uploaded PDFs and images\n",
    "    image_summaries = []\n",
    "    for file in uploaded_files or []:\n",
    "        if file.type == \"application/pdf\":\n",
    "            pdf_reader = PdfReader(file)\n",
    "            full_text = \" \".join(page.extract_text() or \"\" for page in pdf_reader.pages)\n",
    "            if full_text:\n",
    "                chunks = chunk_text(full_text)\n",
    "                embed_and_store_chunks(chunks)\n",
    "                context_chunks.extend(query_relevant_chunks(story_input))\n",
    "        else:\n",
    "            content = file.read()\n",
    "            base64_img = base64.b64encode(content).decode(\"utf-8\")\n",
    "            image_summaries.append(f\"{file.name} (base64): {base64_img[:200]}...\")\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt_parts = [\n",
    "        f\"User Story: {story_input}\",\n",
    "        \"\\nRelevant Docs:\\n\" + \"\\n---\\n\".join(context_chunks) if context_chunks else \"\",\n",
    "        \"\\n\".join(image_summaries) if image_summaries else \"\",\n",
    "        \"\\nWrite a detailed Jira story with clear acceptance criteria.\"\n",
    "    ]\n",
    "\n",
    "    if generate_code:\n",
    "        prompt_parts.append(\"Also generate sample implementation code.\")\n",
    "\n",
    "    full_prompt = \"\\n\\n\".join([part for part in prompt_parts if part])\n",
    "\n",
    "    with st.spinner(\"Thinking with Gemini...\"):\n",
    "        result = gen_model.generate_content(full_prompt)\n",
    "        story_result = result.text\n",
    "\n",
    "    st.subheader(\"üìã Generated Jira Story\")\n",
    "    st.code(story_result)\n",
    "\n",
    "    # Create Jira issue\n",
    "    with st.spinner(\"Creating Jira issue...\"):\n",
    "        headers = {\n",
    "            \"Authorization\": \"Basic \" + base64.b64encode(f\"{JIRA_EMAIL}:{JIRA_API_TOKEN_SECRET}\".encode()).decode(),\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"fields\": {\n",
    "                \"project\": {\"key\": \"YOURPROJECTKEY\"},\n",
    "                \"summary\": story_input,\n",
    "                \"description\": story_result,\n",
    "                \"issuetype\": {\"name\": \"Story\"}\n",
    "            }\n",
    "        }\n",
    "        jira_res = requests.post(JIRA_API_URL, headers=headers, json=payload)\n",
    "        if jira_res.status_code == 201:\n",
    "            st.success(\"‚úÖ Jira ticket created!\")\n",
    "        else:\n",
    "            st.error(f\"‚ùå Failed to create Jira issue: {jira_res.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
