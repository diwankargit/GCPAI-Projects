{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4538319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BeautifulSoup4\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from BeautifulSoup4)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/bhavanakajal/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages (from BeautifulSoup4) (4.14.1)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, BeautifulSoup4\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [BeautifulSoup4]m [BeautifulSoup4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed BeautifulSoup4-4.13.4 soupsieve-2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install BeautifulSoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "befa7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py (Streamlit frontend + backend logic + RAG with GCP Vector Search)\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from google.oauth2 import service_account\n",
    "import base64\n",
    "import json\n",
    "import uuid\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchingEngineIndexEndpoint\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index import MatchingEngineIndex\n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndexEndpoint\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud.aiplatform_v1 import IndexServiceClient\n",
    "from google.cloud.aiplatform_v1.types import IndexDatapoint, UpsertDatapointsRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4649091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "# --- CONFIG ---\n",
    "PROJECT_ID = \"llmdemo-466101\"\n",
    "REGION = \"us-east1\"\n",
    "MODEL = \"gemini-1.5-pro\"\n",
    "EMBED_MODEL = \"gemini-embedding-001\"\n",
    "JIRA_API_URL = \"https://diwankarkumar12.atlassian.net/rest/api/2/issue\"\n",
    "JIRA_EMAIL = \"diwankarkumar12@gmail.com\"\n",
    "JIRA_API_TOKEN_SECRET = \"ATATT3xFfGF0uGy-4sujxTwssEwojy0sCYiXaVuM2dAf5rXa8X0ZP8CxrUZRnk-gfuQ3XjpqH-MeFj7hm6D6dN5eyv-O5Fw4V5rtBtjY9yUx1Quwk7rqUVHnV2c7X6afxKkbfA29OIz9uG2zE3riuhsIFU6gUNRyzrC9p8PJM9Dwk6QCfbyHaRk=DB006359\"\n",
    "INDEX_ENDPOINT_NAME = \"projects/885301403345/locations/us-east1/indexEndpoints/5306089184019087360\"\n",
    "INDEX_ID = \"confulence_embeddings_1753142558399\"\n",
    "api_key_path=\"/Users/bhavanakajal/Documents/GitHub/GCPAI-Projects/keys/llmdemo-466101-3acdef328b4a.json\"\n",
    "ENDPOINT_ID=\"5306089184019087360\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e293c0c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Permission denied on resource project PROJECT_ID. [reason: \"CONSUMER_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"aiplatform.googleapis.com\"\n}\nmetadata {\n  key: \"containerInfo\"\n  value: \"PROJECT_ID\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/PROJECT_ID\"\n}\n, locale: \"en-US\"\nmessage: \"Permission denied on resource project PROJECT_ID.\"\n, links {\n  description: \"Google developers console\"\n  url: \"https://console.developers.google.com\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m aiplatform\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mPROJECT_ID, location\u001b[38;5;241m=\u001b[39mREGION, credentials\u001b[38;5;241m=\u001b[39mcreds)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mMatchingEngineIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojects/PROJECT_ID/locations/us-east1/indexes/INDEX_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m index_endpoint \u001b[38;5;241m=\u001b[39m MatchingEngineIndexEndpoint(\n\u001b[1;32m     15\u001b[0m     index_endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/PROJECT_ID/locations/us-east1/indexEndpoints/ENDPOINT_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index.py:93\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, index_name, project, location, credentials)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     86\u001b[0m         project\u001b[38;5;241m=\u001b[39mproject,\n\u001b[1;32m     87\u001b[0m         location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m     88\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m     89\u001b[0m         resource_name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gca_resource(resource_name\u001b[38;5;241m=\u001b[39mindex_name)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdescription\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Description of the index.\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_gca_resource_is_available()\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:692\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m        Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfull_resource_name(\n\u001b[1;32m    682\u001b[0m     resource_name\u001b[38;5;241m=\u001b[39mresource_name,\n\u001b[1;32m    683\u001b[0m     resource_noun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m     resource_id_validator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_id_validator,\n\u001b[1;32m    690\u001b[0m )\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getter_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_RETRY\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/index_service/client.py:1021\u001b[0m, in \u001b[0;36mget_index\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_indexes\u001b[39m(\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    990\u001b[0m     request: Optional[Union[index_service\u001b[38;5;241m.\u001b[39mListIndexesRequest, \u001b[38;5;28mdict\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    995\u001b[0m     metadata: Sequence[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m (),\n\u001b[1;32m    996\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pagers\u001b[38;5;241m.\u001b[39mListIndexesPager:\n\u001b[1;32m    997\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Lists Indexes in a Location.\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m    .. code-block:: python\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m        # This snippet has been automatically generated and should be regarded as a\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;124;03m        # code template only.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124;03m        # It will require modifications to work:\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;124;03m        # - It may require correct/in-range values for request initialization.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;124;03m        # - It may require specifying regional endpoints when creating the service\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m        #   client as shown in:\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m        #   https://googleapis.dev/python/google-api-core/latest/client_options.html\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m        from google.cloud import aiplatform_v1\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m        def sample_list_indexes():\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m            # Create a client\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m            client = aiplatform_v1.IndexServiceClient()\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m \u001b[38;5;124;03m            # Initialize request argument(s)\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m            request = aiplatform_v1.ListIndexesRequest(\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m                parent=\"parent_value\",\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m            )\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;03m            # Make the request\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03m            page_result = client.list_indexes(request=request)\u001b[39;00m\n\u001b[0;32m-> 1021\u001b[0m \n\u001b[1;32m   1022\u001b[0m \u001b[38;5;124;03m            # Handle the response\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m            for response in page_result:\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;03m                print(response)\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m        request (Union[google.cloud.aiplatform_v1.types.ListIndexesRequest, dict]):\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m            The request object. Request message for\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m            [IndexService.ListIndexes][google.cloud.aiplatform.v1.IndexService.ListIndexes].\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m        parent (str):\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;03m            Required. The resource name of the Location from which\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03m            to list the Indexes. Format:\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m            ``projects/{project}/locations/{location}``\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m            This corresponds to the ``parent`` field\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m            on the ``request`` instance; if ``request`` is provided, this\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m            should not be set.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m        retry (google.api_core.retry.Retry): Designation of what errors, if any,\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m            should be retried.\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m        timeout (float): The timeout for this request.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m        metadata (Sequence[Tuple[str, str]]): Strings which should be\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m            sent along with the request as metadata.\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;124;03m        google.cloud.aiplatform_v1.services.index_service.pagers.ListIndexesPager:\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;124;03m            Response message for\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;124;03m               [IndexService.ListIndexes][google.cloud.aiplatform.v1.IndexService.ListIndexes].\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m            Iterating over this object will yield results and\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03m            resolve additional pages automatically.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;66;03m# Create or coerce a protobuf request object.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# - Quick check: If we got a request object, we should *not* have\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m#   gotten any keyword arguments that map to the request.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     has_flattened_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m([parent])\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    210\u001b[0m         error_list,\n\u001b[1;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    212\u001b[0m         original_timeout,\n\u001b[1;32m    213\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 Permission denied on resource project PROJECT_ID. [reason: \"CONSUMER_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"aiplatform.googleapis.com\"\n}\nmetadata {\n  key: \"containerInfo\"\n  value: \"PROJECT_ID\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/PROJECT_ID\"\n}\n, locale: \"en-US\"\nmessage: \"Permission denied on resource project PROJECT_ID.\"\n, links {\n  description: \"Google developers console\"\n  url: \"https://console.developers.google.com\"\n}\n]"
     ]
    }
   ],
   "source": [
    "# --- INIT SERVICES ---\n",
    "# --- INIT SERVICES ---\n",
    "creds = service_account.Credentials.from_service_account_file(api_key_path)\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "embed_model = TextEmbeddingModel.from_pretrained(EMBED_MODEL)\n",
    "gen_model = GenerativeModel(MODEL)\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "#index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\n",
    "\n",
    "index = MatchingEngineIndex(\n",
    "    index_name=\"projects/PROJECT_ID/locations/us-east1/indexes/INDEX_ID\"\n",
    ")\n",
    "\n",
    "index_endpoint = MatchingEngineIndexEndpoint(\n",
    "    index_endpoint_name=\"projects/PROJECT_ID/locations/us-east1/indexEndpoints/ENDPOINT_ID\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a7033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNCTIONS ---\n",
    "def extract_confluence_text(url):\n",
    "    try:\n",
    "        res = req.get(url)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        return soup.get_text()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text(text, max_words=200):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "def embed_and_store_chunks(chunks):\n",
    "    embeddings = embed_model.get_embeddings(chunks)\n",
    "    datapoints = []\n",
    "    for chunk, embedding in zip(chunks, embeddings):\n",
    "        datapoints.append(\n",
    "            MatchingEngineIndexDatapoint(\n",
    "                datapoint_id=str(uuid.uuid4()),\n",
    "                feature_vector=embedding.values,\n",
    "                metadata={\"text\": chunk}\n",
    "            )\n",
    "        )\n",
    "    index_endpoint.upsert_datapoints(\n",
    "        deployed_index_id=INDEX_ID,\n",
    "        datapoints=datapoints\n",
    "    )\n",
    "\n",
    "def query_relevant_chunks(query, top_k=3):\n",
    "    query_vec = embed_model.get_embeddings([query])[0].values\n",
    "    res = index_endpoint.find_neighbors(\n",
    "        deployed_index_id=INDEX_ID,\n",
    "        queries=[query_vec],\n",
    "        num_neighbors=top_k,\n",
    "        approximate_neighbors_count=1000,\n",
    "        return_full_datapoint=True\n",
    "    )\n",
    "    neighbors = res[0].neighbors\n",
    "    return [neighbor.datapoint.metadata[\"text\"] for neighbor in neighbors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba47c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 22:34:56.896 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.061 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/bhavanakajal/Documents/GitHub/GCPAI-Projects/venv/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-21 22:34:57.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.075 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.089 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.097 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.161 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.171 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.178 Session state does not function when running a script without `streamlit run`\n",
      "2025-07-21 22:34:57.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.226 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.239 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.258 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-21 22:34:57.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# --- STREAMLIT UI ---\n",
    "st.title(\"üß† AI + RAG Jira Story Generator (GCP)\")\n",
    "st.markdown(\"Enter your story and supporting documentation.\")\n",
    "\n",
    "story_input = st.text_input(\"üìù One-line User Story\")\n",
    "confluence_links_input = st.text_area(\"üîó Confluence Page Links (one per line)\", height=100)\n",
    "uploaded_files = st.file_uploader(\"üìÑ Upload PDFs or Diagrams (optional)\", type=[\"pdf\", \"png\", \"jpg\", \"jpeg\"], accept_multiple_files=True)\n",
    "generate_code = st.checkbox(\"üíª Generate Code\")\n",
    "\n",
    "if st.button(\"üöÄ Generate Jira Story\"):\n",
    "    if not story_input:\n",
    "        st.warning(\"Story is required!\")\n",
    "        st.stop()\n",
    "\n",
    "    context_chunks = []\n",
    "\n",
    "    # Process all Confluence links\n",
    "    if confluence_links_input.strip():\n",
    "        for url in confluence_links_input.strip().splitlines():\n",
    "            full_text = extract_confluence_text(url.strip())\n",
    "            if full_text:\n",
    "                chunks = chunk_text(full_text)\n",
    "                embed_and_store_chunks(chunks)\n",
    "                context_chunks.extend(query_relevant_chunks(story_input))\n",
    "\n",
    "    # Process all uploaded PDFs and images\n",
    "    image_summaries = []\n",
    "    for file in uploaded_files or []:\n",
    "        if file.type == \"application/pdf\":\n",
    "            pdf_reader = PdfReader(file)\n",
    "            full_text = \" \".join(page.extract_text() or \"\" for page in pdf_reader.pages)\n",
    "            if full_text:\n",
    "                chunks = chunk_text(full_text)\n",
    "                embed_and_store_chunks(chunks)\n",
    "                context_chunks.extend(query_relevant_chunks(story_input))\n",
    "        else:\n",
    "            content = file.read()\n",
    "            base64_img = base64.b64encode(content).decode(\"utf-8\")\n",
    "            image_summaries.append(f\"{file.name} (base64): {base64_img[:200]}...\")\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt_parts = [\n",
    "        f\"User Story: {story_input}\",\n",
    "        \"\\nRelevant Docs:\\n\" + \"\\n---\\n\".join(context_chunks) if context_chunks else \"\",\n",
    "        \"\\n\".join(image_summaries) if image_summaries else \"\",\n",
    "        \"\\nWrite a detailed Jira story with clear acceptance criteria.\"\n",
    "    ]\n",
    "\n",
    "    if generate_code:\n",
    "        prompt_parts.append(\"Also generate sample implementation code.\")\n",
    "\n",
    "    full_prompt = \"\\n\\n\".join([part for part in prompt_parts if part])\n",
    "\n",
    "    with st.spinner(\"Thinking with Gemini...\"):\n",
    "        result = gen_model.generate_content(full_prompt)\n",
    "        story_result = result.text\n",
    "\n",
    "    st.subheader(\"üìã Generated Jira Story\")\n",
    "    st.code(story_result)\n",
    "\n",
    "    # Create Jira issue\n",
    "    with st.spinner(\"Creating Jira issue...\"):\n",
    "        headers = {\n",
    "            \"Authorization\": \"Basic \" + base64.b64encode(f\"{JIRA_EMAIL}:{JIRA_API_TOKEN_SECRET}\".encode()).decode(),\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"fields\": {\n",
    "                \"project\": {\"key\": \"YOURPROJECTKEY\"},\n",
    "                \"summary\": story_input,\n",
    "                \"description\": story_result,\n",
    "                \"issuetype\": {\"name\": \"Story\"}\n",
    "            }\n",
    "        }\n",
    "        jira_res = requests.post(JIRA_API_URL, headers=headers, json=payload)\n",
    "        if jira_res.status_code == 201:\n",
    "            st.success(\"‚úÖ Jira ticket created!\")\n",
    "        else:\n",
    "            st.error(f\"‚ùå Failed to create Jira issue: {jira_res.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085030cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py (Streamlit frontend + backend logic + RAG with GCP Vector Search)\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "from google.oauth2 import service_account\n",
    "import base64\n",
    "import json\n",
    "import uuid\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import MatchingEngineIndexEndpoint\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index import MatchingEngineIndex\n",
    "\n",
    "# --- CONFIG ---\n",
    "PROJECT_ID = \"llmdemo-466101\"\n",
    "REGION = \"us-east1\"\n",
    "MODEL = \"gemini-1.5-pro\"\n",
    "EMBED_MODEL = \"textembedding-gecko@001\"\n",
    "JIRA_API_URL = \"https://diwankarkumar12.atlassian.net/rest/api/2/issue\"\n",
    "JIRA_EMAIL = \"diwankarkumar12@gmail.com\"\n",
    "JIRA_API_TOKEN_SECRET = \"ATATT3xFfGF0uGy-4sujxTwssEwojy0sCYiXaVuM2dAf5rXa8X0ZP8CxrUZRnk-gfuQ3XjpqH-MeFj7hm6D6dN5eyv-O5Fw4V5rtBtjY9yUx1Quwk7rqUVHnV2c7X6afxKkbfA29OIz9uG2zE3riuhsIFU6gUNRyzrC9p8PJM9Dwk6QCfbyHaRk=DB006359\"\n",
    "INDEX_ENDPOINT_NAME = \"projects/885301403345/locations/us-east1/indexEndpoints/5306089184019087360\"\n",
    "INDEX_ID = \"confulence_embeddings_1753142558399\"\n",
    "\n",
    "# --- INIT SERVICES ---\n",
    "creds = service_account.Credentials.from_service_account_file(\"path/to/service-account.json\")\n",
    "vertexai.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "embed_model = TextEmbeddingModel.from_pretrained(EMBED_MODEL)\n",
    "gen_model = GenerativeModel(MODEL)\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, credentials=creds)\n",
    "index_endpoint = MatchingEngineIndexEndpoint(index_endpoint_name=INDEX_ENDPOINT_NAME)\n",
    "\n",
    "# --- FUNCTIONS ---\n",
    "def extract_confluence_text(url):\n",
    "    try:\n",
    "        res = req.get(url)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        return soup.get_text()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text(text, max_words=200):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "def embed_and_store_chunks(chunks):\n",
    "    embeddings = embed_model.get_embeddings(chunks)\n",
    "    datapoints = []\n",
    "    for chunk, embedding in zip(chunks, embeddings):\n",
    "        datapoints.append(\n",
    "            MatchingEngineIndexDatapoint(\n",
    "                datapoint_id=str(uuid.uuid4()),\n",
    "                feature_vector=embedding.values,\n",
    "                metadata={\"text\": chunk}\n",
    "            )\n",
    "        )\n",
    "    index_endpoint.upsert_datapoints(\n",
    "        deployed_index_id=INDEX_ID,\n",
    "        datapoints=datapoints\n",
    "    )\n",
    "\n",
    "def query_relevant_chunks(query, top_k=3):\n",
    "    query_vec = embed_model.get_embeddings([query])[0].values\n",
    "    res = index_endpoint.find_neighbors(\n",
    "        deployed_index_id=INDEX_ID,\n",
    "        queries=[query_vec],\n",
    "        num_neighbors=top_k,\n",
    "        approximate_neighbors_count=1000,\n",
    "        return_full_datapoint=True\n",
    "    )\n",
    "    neighbors = res[0].neighbors\n",
    "    return [neighbor.datapoint.metadata[\"text\"] for neighbor in neighbors]\n",
    "\n",
    "# --- STREAMLIT UI ---\n",
    "st.title(\"üß† AI + RAG Jira Story Generator (GCP)\")\n",
    "st.markdown(\"Enter your story and supporting documentation.\")\n",
    "\n",
    "story_input = st.text_input(\"üìù One-line User Story\")\n",
    "confluence_links_input = st.text_area(\"üîó Confluence Page Links (one per line)\", height=100)\n",
    "uploaded_files = st.file_uploader(\"üìÑ Upload PDFs or Diagrams (optional)\", type=[\"pdf\", \"png\", \"jpg\", \"jpeg\"], accept_multiple_files=True)\n",
    "generate_code = st.checkbox(\"üíª Generate Code\")\n",
    "\n",
    "if st.button(\"üöÄ Generate Jira Story\"):\n",
    "    if not story_input:\n",
    "        st.warning(\"Story is required!\")\n",
    "        st.stop()\n",
    "\n",
    "    context_chunks = []\n",
    "\n",
    "    # Process all Confluence links\n",
    "    if confluence_links_input.strip():\n",
    "        for url in confluence_links_input.strip().splitlines():\n",
    "            full_text = extract_confluence_text(url.strip())\n",
    "            if full_text:\n",
    "                chunks = chunk_text(full_text)\n",
    "                embed_and_store_chunks(chunks)\n",
    "                context_chunks.extend(query_relevant_chunks(story_input))\n",
    "\n",
    "    # Process all uploaded PDFs and images\n",
    "    image_summaries = []\n",
    "    for file in uploaded_files or []:\n",
    "        if file.type == \"application/pdf\":\n",
    "            pdf_reader = PdfReader(file)\n",
    "            full_text = \" \".join(page.extract_text() or \"\" for page in pdf_reader.pages)\n",
    "            if full_text:\n",
    "                chunks = chunk_text(full_text)\n",
    "                embed_and_store_chunks(chunks)\n",
    "                context_chunks.extend(query_relevant_chunks(story_input))\n",
    "        else:\n",
    "            content = file.read()\n",
    "            base64_img = base64.b64encode(content).decode(\"utf-8\")\n",
    "            image_summaries.append(f\"{file.name} (base64): {base64_img[:200]}...\")\n",
    "\n",
    "    # Construct prompt\n",
    "    prompt_parts = [\n",
    "        f\"User Story: {story_input}\",\n",
    "        \"\\nRelevant Docs:\\n\" + \"\\n---\\n\".join(context_chunks) if context_chunks else \"\",\n",
    "        \"\\n\".join(image_summaries) if image_summaries else \"\",\n",
    "        \"\\nWrite a detailed Jira story with clear acceptance criteria.\"\n",
    "    ]\n",
    "\n",
    "    if generate_code:\n",
    "        prompt_parts.append(\"Also generate sample implementation code.\")\n",
    "\n",
    "    full_prompt = \"\\n\\n\".join([part for part in prompt_parts if part])\n",
    "\n",
    "    with st.spinner(\"Thinking with Gemini...\"):\n",
    "        result = gen_model.generate_content(full_prompt)\n",
    "        story_result = result.text\n",
    "\n",
    "    st.subheader(\"üìã Generated Jira Story\")\n",
    "    st.code(story_result)\n",
    "\n",
    "    # Create Jira issue\n",
    "    with st.spinner(\"Creating Jira issue...\"):\n",
    "        headers = {\n",
    "            \"Authorization\": \"Basic \" + base64.b64encode(f\"{JIRA_EMAIL}:{JIRA_API_TOKEN_SECRET}\".encode()).decode(),\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        payload = {\n",
    "            \"fields\": {\n",
    "                \"project\": {\"key\": \"YOURPROJECTKEY\"},\n",
    "                \"summary\": story_input,\n",
    "                \"description\": story_result,\n",
    "                \"issuetype\": {\"name\": \"Story\"}\n",
    "            }\n",
    "        }\n",
    "        jira_res = requests.post(JIRA_API_URL, headers=headers, json=payload)\n",
    "        if jira_res.status_code == 201:\n",
    "            st.success(\"‚úÖ Jira ticket created!\")\n",
    "        else:\n",
    "            st.error(f\"‚ùå Failed to create Jira issue: {jira_res.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
